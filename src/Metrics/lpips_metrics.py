import torch
from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity

import torchvision.transforms as transforms
from PIL import Image

#lpips = LearnedPerceptualImagePatchSimilarity(net_type = 'vgg')
lpips = LearnedPerceptualImagePatchSimilarity(net_type = 'alex')

# load image in RGB mode (png files contains additional alpha channel)
img1_original = Image.open("image_original.jpg").convert('RGB')
img2_original = Image.open("image2_original.jpg").convert('RGB')
img3 = Image.open('image_has_primary_color_black.jpg').convert('RGB')
img4 = Image.open('image_has_primary_color_brown.jpg').convert('RGB')
img5 = Image.open('image_has_underparts_color_black.jpg').convert('RGB')
img6 = Image.open('image_has_underparts_color_brown.jpg').convert('RGB')
img7 = Image.open('image_has_upperparts_color_brown.jpg').convert('RGB')
img8 = Image.open('image2_has_primary_color_black.jpg').convert('RGB')
img9 = Image.open('image2_has_primary_color_brown.jpg').convert('RGB')
img10 = Image.open('image2_has_underparts_color_black.jpg').convert('RGB')
img11 = Image.open('image2_has_upperparts_color_brown.jpg').convert('RGB')
#img12 = Image.open('White_Breasted_Kingfisher_0012_73367_s-1.png').convert('RGB')


# set up transformation to resize the image
resize = transforms.Resize([224, 224])
img1_original = resize(img1_original)
img2_original = resize(img2_original)
img3 = resize(img3)
img4 = resize(img4)
img5 = resize(img5)
img6 = resize(img6)
img7 = resize(img7)
img8 = resize(img8)
img9 = resize(img9)
img10 = resize(img10)
img11 = resize(img11)
img12 = resize(img12)
to_tensor = transforms.ToTensor()

# apply transformation and convert to Pytorch tensor
tensor1 = to_tensor(img1_original)
tensor2 = to_tensor(img2_original)
tensor3 = to_tensor(img3)
tensor4 = to_tensor(img4)
tensor5 = to_tensor(img5)
tensor6 = to_tensor(img6)
tensor7 = to_tensor(img7)
tensor8 = to_tensor(img8)
tensor9 = to_tensor(img9)
tensor10 = to_tensor(img10)
tensor11 = to_tensor(img11)
tensor12 = to_tensor(img12)
#torch.Size([3, 224, 224])

# add another dimension at the front to get NCHW shape
tensor1 = tensor1.unsqueeze(0)
tensor2 = tensor2.unsqueeze(0)
tensor3 = tensor3.unsqueeze(0)
tensor4 = tensor4.unsqueeze(0)
tensor5 = tensor5.unsqueeze(0)
tensor6 = tensor6.unsqueeze(0)
tensor7 = tensor7.unsqueeze(0)
tensor8 = tensor8.unsqueeze(0)
tensor9 = tensor9.unsqueeze(0)
tensor10 = tensor10.unsqueeze(0)
tensor11 = tensor11.unsqueeze(0)
tensor12 = tensor12.unsqueeze(0)

print('lpips score for Black Footed Albatross with image_has_primary_color_black: ')
print(lpips(tensor1,tensor3))
print('lpips score for Black Footed Albatross with image_has_primary_color_brown: ')
print(lpips(tensor1,tensor4))
print('lpips score for Black Footed Albatross with image_has_underparts_color_black: ')
print(lpips(tensor1,tensor5))
print('lpips score for Black Footed Albatross with image_has_underparts_color_brown: ')
print(lpips(tensor1,tensor6))
print('lpips score for Black Footed Albatross with image_has_upperparts_color_brown: ')
print(lpips(tensor1,tensor7))
print('lpips score for Black Tern with image_has_primary_color_black: ')
print(lpips(tensor2,tensor8))
print('lpips score for Black Tern with image2_has_primary_color_brown: ')
print(lpips(tensor2,tensor9))
print('lpips score for Black Tern with image2_has_underparts_color_black: ')
print(lpips(tensor2,tensor10))
print('lpips score for Black Tern with image2_has_upperparts_color_brown: ')
print(lpips(tensor2,tensor11))
